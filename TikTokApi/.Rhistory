t<-t.test(y1,y2, var.equal=FALSE)
pval[i]<-t$p.value
if (pval[i]>=0.05){
donotreject=donotreject+1
}else{
donotreject=donotreject
}}
donotreject
type2=donotreject/nreps
type2
power=1-type2
power
set.seed(100)
nreps=1000
pval<-numeric(nreps)
donotreject=0
for (i in 1:nreps){
y1<- c(rnorm(sample*.9, 2, 1), rnorm(sample*.1, 2, 10))
y2<- c(rnorm(sample*.55, 5, 1), rnorm(sample*.45, 5, 29))
t<-t.test(y1,y2, var.equal=FALSE)
pval[i]<-t$p.value
if (pval[i]>=0.05){
donotreject=donotreject+1
}else{
donotreject=donotreject
}}
donotreject
type2=donotreject/nreps
type2
power=1-type2
power
set.seed(100)
nreps=1000
pval<-numeric(nreps)
donotreject=0
for (i in 1:nreps){
y1<- c(rnorm(sample*.9, 2, 1), rnorm(sample*.1, 2, 10))
y2<- c(rnorm(sample*.55, 5, 1), rnorm(sample*.45, 5, 20))
t<-t.test(y1,y2, var.equal=FALSE)
pval[i]<-t$p.value
if (pval[i]>=0.05){
donotreject=donotreject+1
}else{
donotreject=donotreject
}}
donotreject
type2=donotreject/nreps
type2
power=1-type2
power
set.seed(100)
nreps=1000
pval<-numeric(nreps)
donotreject=0
for (i in 1:nreps){
y1<- c(rnorm(sample*.9, 2, 1), rnorm(sample*.1, 2, 10))
y2<- c(rnorm(sample*.55, 5, 1), rnorm(sample*.45, 4, 10))
t<-t.test(y1,y2, var.equal=FALSE)
pval[i]<-t$p.value
if (pval[i]>=0.05){
donotreject=donotreject+1
}else{
donotreject=donotreject
}}
donotreject
type2=donotreject/nreps
type2
power=1-type2
power
set.seed(100)
nreps=1000
pval<-numeric(nreps)
donotreject=0
for (i in 1:nreps){
y1<- c(rnorm(sample*.9, 2, 1), rnorm(sample*.1, 2, 10))
y2<- c(rnorm(sample*.55, 5, 1), rnorm(sample*.45, 3, 10))
t<-t.test(y1,y2, var.equal=FALSE)
pval[i]<-t$p.value
if (pval[i]>=0.05){
donotreject=donotreject+1
}else{
donotreject=donotreject
}}
donotreject
type2=donotreject/nreps
type2
power=1-type2
power
set.seed(100)
nreps=1000
pval<-numeric(nreps)
donotreject=0
for (i in 1:nreps){
y1<- c(rnorm(sample*.9, 2, 1), rnorm(sample*.1, 2, 10))
y2<- c(rnorm(sample*.55, 5, 1), rnorm(sample*.45, 2, 10))
t<-t.test(y1,y2, var.equal=FALSE)
pval[i]<-t$p.value
if (pval[i]>=0.05){
donotreject=donotreject+1
}else{
donotreject=donotreject
}}
donotreject
type2=donotreject/nreps
type2
power=1-type2
power
set.seed(100)
nreps=1000
pval<-numeric(nreps)
donotreject=0
for (i in 1:nreps){
y1<- c(rnorm(sample*.9, 2, 1), rnorm(sample*.1, 2, 10))
y2<- c(rnorm(sample*.55, 5, 1), rnorm(sample*.45, 1, 10))
t<-t.test(y1,y2, var.equal=FALSE)
pval[i]<-t$p.value
if (pval[i]>=0.05){
donotreject=donotreject+1
}else{
donotreject=donotreject
}}
donotreject
type2=donotreject/nreps
type2
power=1-type2
power
gf_density(~AGE|Gender1Male, data=body) # 1 = male
gf_qq(~AGE|Gender1Male, data=body) %>% gf_qqline()
bodyM<-filter(body,Gender1Male=="1")
skewness(bodyM$AGE)
kurtosis(bodyM$AGE)
ks.test(bodyM$AGE, "pnorm")
bodyW<-filter(body,Gender1Male=="0")
skewness(bodyW$AGE)
kurtosis(bodyW$AGE)
ks.test(bodyW$AGE, "pnorm")
jarque.test(bodyM$AGE)
jarque.test(bodyW$AGE)
skewness(bodyM$AGE)
kurtosis(bodyM$AGE)
ks.test(bodyM$AGE, "pnorm")
skewness(bodyW$AGE)
kurtosis(bodyW$AGE)
ks.test(bodyW$AGEx, "pnorm")
ks.test(bodyW$AGE, "pnorm")
jarque.test(bodyM$AGE)
jarque.test(bodyW$AGE)
bodyM<-filter(body,Gender1Male=="1")
skewness(bodyM$HT)
skewness(bodyM$HT)
kurtosis(bodyM$HT)
ks.test(bodyM$HT, "pnorm")
skewness(bodyW$HT)
kurtosis(bodyW$HT)
ks.test(bodyW$HT, "pnorm")
jarque.test(bodyM$HT)
jarque.test(bodyW$HT)
skewness(bodyM$CHOL)
kurtosis(bodyM$CHOL)
ks.test(bodyM$CHOL, "pnorm")
skewness(bodyW$CHOL)
kurtosis(bodyW$CHOL) #
ks.test(bodyW$CHOL, "pnorm")
jarque.test(bodyM$CHOL)
jarque.test(bodyW$CHOL)
library(mosaic)
library(car)
library(moments)
library(readxl)
body <- read_excel("Body Characteristics copy 2.xlsx")
gf_density(~AGE|Gender1Male, data=body) # 1 = male
gf_qq(~AGE|Gender1Male, data=body) %>% gf_qqline()
bodyM<-filter(body,Gender1Male=="1")
skewness(bodyM$AGE) # 0.6114
kurtosis(bodyM$AGE) # 2.632
ks.test(bodyM$AGE, "pnorm") # pval < 0.001
bodyW<-filter(body,Gender1Male=="0")
skewness(bodyW$AGE) #0.4522
kurtosis(bodyW$AGE) # 2.283
ks.test(bodyW$AGE, "pnorm") # pval < 0.001
jarque.test(bodyM$AGE) # pval = 0.3
jarque.test(bodyW$AGE) #pval =  0.3
gf_density(~HT|Gender1Male, data=body) # 1 = male
gf_qq(~HT|Gender1Male, data=body) %>% gf_qqline()
skewness(bodyM$HT) # 0.0439
kurtosis(bodyM$HT) # 3.298
ks.test(bodyM$HT, "pnorm") # pval < 0.001
skewness(bodyW$HT) # -0.123
kurtosis(bodyW$HT) # 2.475
ks.test(bodyW$HT, "pnorm") # pval < 0.001
jarque.test(bodyM$HT) # pval = 0.9
jarque.test(bodyW$HT) # pval = 0.8
gf_density(~CHOL|Gender1Male, data=body) # 1 = male
gf_qq(~CHOL|Gender1Male, data=body) %>% gf_qqline()
skewness(bodyM$CHOL) # 0.9299
kurtosis(bodyM$CHOL) # 3.268
ks.test(bodyM$CHOL, "pnorm") # pval < 0.001
skewness(bodyW$CHOL) # 1.54
kurtosis(bodyW$CHOL) # 5.993
ks.test(bodyW$CHOL, "pnorm") # pval < 0.001
jarque.test(bodyM$CHOL) # pval = 0.05
jarque.test(bodyW$CHOL) # pval < 0.001
n <- 1000
mixed.norm <- c(rnorm(n*.99, 2,1), rnorm(n*.01, 2, 1))
gf_density(~mixed.norm)
gf_qq(~mixed.norm) %>% gf_qqline()
skewness(mixed.norm)
kurtosis(mixed.norm)
ks.test(mixed.norm, "pnorm")
jarque.test(mixed.norm)
mixed.norm3 <- c(rnorm(n*.99, 2,1), rnorm(n*.01, 2, 3))
gf_density(~mixed.norm3)
gf_qq(~mixed.norm3) %>% gf_qqline()
skewness(mixed.norm3)
kurtosis(mixed.norm3)
ks.test(mixed.norm3, "pnorm")
jarque.test(mixed.norm3)
mixed.norm5 <- c(rnorm(n*.99, 2,1), rnorm(n*.01, 2, 5))
gf_density(~mixed.norm5)
gf_qq(~mixed.norm5) %>% gf_qqline()
skewness(mixed.norm5)
kurtosis(mixed.norm5)
ks.test(mixed.norm5, "pnorm")
jarque.test(mixed.norm5)
mixed.norm3.2 <- c(rnorm(n*.97, 2,1), rnorm(n*.03, 2, 3))
gf_density(~mixed.norm3.2)
gf_qq(~mixed.norm3.2) %>% gf_qqline()
skewness(mixed.norm3.2)
kurtosis(mixed.norm3.2)
ks.test(mixed.norm3.2, "pnorm")
jarque.test(mixed.norm3.2)
mixed.norm3.3 <- c(rnorm(n*.95, 2,1), rnorm(n*.05, 2, 3))
gf_density(~mixed.norm3.3)
gf_qq(~mixed.norm3.3) %>% gf_qqline()
skewness(mixed.norm3.3)
kurtosis(mixed.norm3.3)
ks.test(mixed.norm3.3, "pnorm")
jarque.test(mixed.norm3.3)
sample <- 100
mixed.sample <- c(rnorm(sample*.9, 2, 1), rnorm(sample*.1, 2, 10))
set.seed(100)
nreps=1000
pval<-numeric(nreps)
donotreject=0
for (i in 1:nreps){
y1<- c(rnorm(sample*.9, 2, 1), rnorm(sample*.1, 2, 10))
y2<- c(rnorm(sample*.55, 5, 1), rnorm(sample*.45, 5, 10))
t<-t.test(y1,y2, var.equal=FALSE)
pval[i]<-t$p.value
if (pval[i]>=0.05){
donotreject=donotreject+1
}else{
donotreject=donotreject
}}
donotreject
type2=donotreject/nreps
type2
power=1-type2
power
set.seed(100)
nreps=1000
pval<-numeric(nreps)
donotreject=0
for (i in 1:nreps){
y1<- c(rnorm(sample*.9, 2, 1), rnorm(sample*.1, 2, 10))
y2<- c(rnorm(sample*.55, 5, 1), rnorm(sample*.45, 5, 20))
t<-t.test(y1,y2, var.equal=FALSE)
pval[i]<-t$p.value
if (pval[i]>=0.05){
donotreject=donotreject+1
}else{
donotreject=donotreject
}}
donotreject
type2=donotreject/nreps
type2
power=1-type2
power
set.seed(100)
nreps=1000
pval<-numeric(nreps)
donotreject=0
for (i in 1:nreps){
y1<- c(rnorm(sample*.9, 2, 1), rnorm(sample*.1, 2, 10))
y2<- c(rnorm(sample*.55, 5, 1), rnorm(sample*.45, 1, 10))
t<-t.test(y1,y2, var.equal=FALSE)
pval[i]<-t$p.value
if (pval[i]>=0.05){
donotreject=donotreject+1
}else{
donotreject=donotreject
}}
donotreject
type2=donotreject/nreps
type2
power=1-type2
power
library(mosaic)
library(MUsaic)
library(MKmisc)
#install.packages("coin") has permutation tests
library(coin)
library(mosaic)
library(MUsaic)
library(MKmisc)
#install.packages("coin") has permutation tests
library(coin)
library(mosaic)
library(MUsaic)
library(MKmisc)
#install.packages("coin") has permutation tests
library(coin)
load("weeds.rda")
View(weeds)
gf_histogram(~crop.yield |condition, data=weeds)
gf_density(~crop.yield |condition, data=weeds)
gf_qq(~crop.yield | condition,data=weeds) %>% gf_qqline
#The next code puts both qq plots on 1 graph with different colors
gf_qq(~crop.yield, col = ~condition,data=weeds) %>% gf_qqline
# We could use all the tests from Lesson on NOrmality, but to save time we'll move on
weeds0<-filter(weeds,condition =="no.weeds")
weeds3<-filter(weeds,condition == "three.weeds")
ks.test(weeds0$crop.yield,weeds3$crop.yield)
# Remove existing rank column (column 3)
# code means make new dataset called weeds1 that is weeds with column 3 removed in all rows [ , -3]. The [ , ] notation is [row number, col number]
weeds1=weeds[,-3]
weeds1
#R code notation: datasetname$variablename means access (or create if not already there) the variable in the variablename column of dataset datasetname.
# the code rank(weeds1$crop.yield) perfoms the function rank on the cropyield variable in dataset weeds1.
#This command means make a new column variable in weeds1 called rank. Define that variable as the ranking of the variable crop.yield.
weeds1$rank=rank(weeds1$crop.yield)
weeds1
#generic code for this operation is
# datasetname[order(datsetname$variablename), ]
#the $ means get the data in the column variablename and the blank after the comma means get this data for every row
weeds1[order(weeds1$crop.yield), ]
wilcox.test(crop.yield~condition,data=weeds, alternative="greater")
t.test(crop.yield~condition,data=weeds, alternative ="greater", paired=FALSE)
# install.packages('doParallel')
library(doParallel)
cl <- makeCluster(8)
registerDoParallel(cl)
which.user <- 31
# Read in by-week data as data.frame.
dat <- read.table(sprintf('BinSeq-MatrixWSpaces/matrix-%g.txt', which.user), sep = ' ', header = FALSE)
# Convert to matrix
dat <- data.matrix(dat)
# Take transpose to make column-oriented (one week per column), so
# can flatten easily into long vector.
Y <- t(dat)
# Flatten matrix to long vector.
dim(Y) <- NULL
# Get out design points as clock times.
x <- rep(1:ncol(dat), nrow(dat))
par(mfrow = c(1, 2))
plot(Y, pch = 16, cex = 0.1)
plot(x, Y, pch = 16, cex = 0.1)
library(gam)
source('cv-clock-gam.R')
cv.out <- cv.clock.gam(dat)
plot(cv.out$spars, cv.out$negative.LLs,
xlab = 'Smoothing Parameter',
ylab = 'CV-ed Negative Log-Likelihood')
abline(v = cv.out$spar.star)
mod <- gam(Y ~ s(x, spar = cv.out$spar.star), family = binomial)
plot(predict(mod, type = 'response')[1:ncol(dat)], type = 'l', ylim = c(0, 0.2),
xlab = 'Time (1/2 Hour Segments)', ylab = 'Probability User is Active')
points(x, Y*0.2, pch = 16, cex = 0.1)
# Add smoothing spline fit via least-squares for comparison
lines(smooth.spline(x, Y), col = 'red', lty = 2)
# install.packages('doParallel')
library(doParallel)
cl <- makeCluster(8)
registerDoParallel(cl)
which.user <- 1
# Read in by-week data as data.frame.
dat <- read.table(sprintf('BinSeq-MatrixWSpaces/matrix-%g.txt', which.user), sep = ' ', header = FALSE)
# Convert to matrix
dat <- data.matrix(dat)
# Take transpose to make column-oriented (one week per column), so
# can flatten easily into long vector.
Y <- t(dat)
# Flatten matrix to long vector.
dim(Y) <- NULL
# Get out design points as clock times.
x <- rep(1:ncol(dat), nrow(dat))
par(mfrow = c(1, 2))
plot(Y, pch = 16, cex = 0.1)
plot(x, Y, pch = 16, cex = 0.1)
library(gam)
source('cv-clock-gam.R')
cv.out <- cv.clock.gam(dat)
plot(cv.out$spars, cv.out$negative.LLs,
xlab = 'Smoothing Parameter',
ylab = 'CV-ed Negative Log-Likelihood')
abline(v = cv.out$spar.star)
mod <- gam(Y ~ s(x, spar = cv.out$spar.star), family = binomial)
plot(predict(mod, type = 'response')[1:ncol(dat)], type = 'l', ylim = c(0, 0.2),
xlab = 'Time (1/2 Hour Segments)', ylab = 'Probability User is Active')
points(x, Y*0.2, pch = 16, cex = 0.1)
# Add smoothing spline fit via least-squares for comparison
lines(smooth.spline(x, Y), col = 'red', lty = 2)
#setwd("~/Documents/HonorsThesis/HonThesis-OdalysBar/extract-from-odalyss-list/data")
library(anytime)
#install.packages("reticulate")
library(reticulate)
use_python("/Users/odalysbar/opt/anaconda3/bin/python")
getwd()
library(readr)
#addisonre <- read_csv("/Users/odalysbar/Documents/HonorsThesis/transCSSR-master/TikTokApi/HonThesis-OdalysBar/extract-from-odalyss-list/FamousUsersCSV/addisonre.csv")
#View(addisonre)
#addisonre
# timestamps <- rev(addisonre$createTime) # oldest to earliest time
# hist(timestamps,breaks =100) # unixtime in sec
#
# timemin <- timestamps/60 # unixtime in min
# hist(timemin, breaks = 100)
#
# timehr <- timemin/60 # unixtime in hours
# hist(timehr, breaks = 100)
# frequency of time between post in min
# hist(diff(timemin),breaks="FD",xlim= c(0,10000), ylim = c(0,200))
# frequency of time between post in hours
# hist(diff(timehr),breaks="FD",xlim= c(0,10000/60), ylim = c(0,200))
# head(timemin)
# tail(timemin)
# interval <- 30
# time.old <- timemin[1]
# time.new <- timemin[1] + interval
# binary <- vector()
# i <- 1
# last <- length(timemin) # 1363
#
# while(time.new <= timemin[last]){ # after time.new = the last time we want to stop looking
#
#   index <- which(timemin <= time.new & timemin > time.old) # which times are in the interval of 10 min
#   if(sum(index) == 0){ # if there are no values on the interval
#     binary[i] <- 0 # 0 = not avtive
#   }else{
#     binary[i] <- 1 # 1 = active
#   }
#   time.old <- time.new # replace new time with old
#   time.new <- time.new + interval # add 10 min to new time
#   i <- i + 1  # we will repeat with a new interval of 10min
# }
# binary
# sum(binary)
# length(binary)
# sum(binary)/length(binary)
# 1. Binary sequence as vector ex: 0,1,0,0,1
# 2. Binary sequence as list
# where there should be the a 1 there are the index of post that were posted at the time interval we are looking as
# ex: 0,2,0,5,0,0 <--- as list
# start.time <- min(timemin)
# end.time <- max(timemin)
# interval <- 30
#
# newtime <- start.time + interval
# bins <- c(start.time, newtime)
# i <- 3
# while(newtime <= end.time + interval){
#   bins[i] <- newtime + interval
#   newtime <- bins[i]
#   i <- i + 1
# }
# # bins
#
# index <- vector()
# #index <- list()
# for(i in 1:(length(bins)-1)){
#   if(sum(which(timemin <= bins[i+1] & timemin > bins[i]))==0){
#     index[i] <- 0
#     #index[[i]] <- 0
#   }else{
#     index[i] <- 1
#     #index[[i]]<-c(which(timemin <= bins[i+1] & timemin > bins[i]))
#   }
# }
# #index
# sum(index)/length(index)
# bin.num <- ((timemin-min(timemin))%/%30)+1
# #bin.num
#
# binary.seq <- c(rep(0,length.out=max(bin.num)))
#
# binary.seq[bin.num] <- 1
# binary.seq
#
# sum(binary.seq)/length(binary.seq)
source("DataCollectionFun.R")
jan1.18 <- 1546318800/60 # start time
april13.21 <- 26971697 # end time
# matrix1 <- list.out$weeklymatrix.users[1]
# matrix1.longstring <- paste0(matrix1[[1]][1,])
# matrix1.longstring
# paste(matrix1.longstring, collapse = "")
# writeLines(matrix1.longstring, con = stdout(), sep = " ",)]
# txt <- c("Hallo", "World", "Odalys")
# writeLines(txt, "outfile.txt")
jan1.18 <- 1546318800/60 # start time
april13.21 <- 26971697 # end time
list.out <- save.binseq(starttime = jan1.18, endtime = april13.21)
list.out <- save.binseq(starttime = jan1.18, endtime = april13.21)
v
source("DataCollectionFun.R")
list.out <- save.binseq(starttime = jan1.18, endtime = april13.21)
source("DataCollectionFun.R")
list.out <- save.binseq(starttime = jan1.18, endtime = april13.21)
mat.log <- list.outx$matrixbyintervals
mat.log <- list.out$matrixbyintervals
mat <- list.out$weeklymatrix.users
users <- list.out$users
